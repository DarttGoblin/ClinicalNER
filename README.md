# ğŸ§¬ ClinicalNER: Named Entity Recognition in Biomedical Literature

Welcome to the official repository for **ClinicalNER**, a clinical Named Entity Recognition system that extracts biomedical entities â€” diseases, symptoms, genes, and proteins â€” from real PubMed abstracts using distant supervision and deep learning models.

---

## ğŸ“Œ Project Overview

ClinicalNER was developed as part of an NLP research project to build a scalable biomedical NER system using:

- ğŸ“š **Real abstracts** collected from PubMed
- ğŸ§  **Distant supervision** for automatic annotation
- ğŸ¤– Deep learning models (BiLSTM and BiLSTM+CRF)
- ğŸ“Š Sequence labeling evaluation (Precision, Recall, F1)

---

## ğŸ—‚ï¸ Project Structure

ClinicalNER_Project/
â”‚
â”œâ”€â”€ ClinicalNER.ipynb # Main training and evaluation notebook
â”‚
â”œâ”€â”€ other_files/ # Extra/temporary JSONL files from scraping or annotation
â”‚ â”œâ”€â”€ pubmed_abstracts.jsonl
â”‚ â”œâ”€â”€ BioPortal_annotation_dataset.jsonl
â”‚ â””â”€â”€ ... (cleaned/preprocessed versions)
â”‚
â”œâ”€â”€ data/ # Final cleaned data used for training
â”‚ â”œâ”€â”€ pubmed_abstracts.txt # Raw PubMed abstracts (6000)
â”‚ â”œâ”€â”€ pubmed_abstracts_labled.txt # BIO-labeled file for BiLSTM(+CRF)
â”‚ â””â”€â”€ biobert_ner_data.tsv # TSV-formatted version for BioBERT
â”‚
â”œâ”€â”€ models/ # Trained model files
â”‚ â”œâ”€â”€ BiLSTM.pt
â”‚ â”œâ”€â”€ BiLSTM-CRF.pt
â”‚ â””â”€â”€ BiLSTM-CRF_full.pth


---

## ğŸš€ How It Works

### 1. ğŸ“¥ Data Collection
We extracted 6000 abstracts from PubMed using 30 queries per entity type (disease, gene, symptom, protein), 50 abstracts each.

### 2. ğŸ§¹ Preprocessing
- Sentence segmentation and tokenization (`spaCy`)
- Text normalization
- Removal of headers and metadata

### 3. ğŸ·ï¸ Distant Supervision
Using hand-crafted dictionaries, we applied weak labeling using BIO tags:
- `B-DISEASE`, `I-GENE`, `O`, etc.
- Ambiguous terms (e.g., `"MAP"`, `"SET"`) filtered out for gene/protein

### 4. ğŸ§  Models
Two models were implemented:
- `BiLSTM` (baseline)
- `BiLSTM + CRF` (improved with sequence-level decoding)

### 5. ğŸ“Š Evaluation
We used `seqeval` to compute:
- Precision, Recall, F1-score
- Entity-wise + micro/macro averages

---

## âš™ï¸ How to Use This Repo

> Run everything from `ClinicalNER.ipynb` (Colab/Locally)

### ğŸ”§ Requirements

Install required packages:
```bash
pip install torch transformers seqeval spacy biopython
python -m spacy download en_core_web_sm

â–¶ï¸ To Train Models
Load and preprocess data

Run BiLSTM training block

Run BiLSTM + CRF training block

Evaluate using seqeval

ğŸ“ˆ Model Performance
Model       	Prs 	Rcl	    F1-s
BiLSTM	        0.00	0.00	0.00
BiLSTM + CRF	1.00	1.00	1.00

ğŸŸ¢ CRF improved tagging performance drastically by modeling label sequences.

âš ï¸ Known Limitations
âŒ BioBERT was not successfully trained due to sequence length errors (abstracts > 512 tokens).

ğŸŸ¡ The dataset is weakly labeled, so results are optimistic â€” real-world performance needs validation on manually annotated corpora.

ğŸ§  Authors
ğŸ‘© Zahra Abouhane

ğŸ§‘ Project Partner(s) (if any)

ğŸ« University: UCA, NLP M2

ğŸ“š Citation
If you use this work, please cite or credit the project in your research/report.

ğŸ“¬ Contact
For any question or feedback, open an issue or contact abouhanezahra@uca.ac.ma

ğŸŒ± Future Work
âœ… Finish BioBERT training with sequence truncation

ğŸ§ª Add real manually labeled test set

ğŸ“– Explore transfer learning with PubMedBERT

ğŸ§¬ ClinicalNER â€“ because biomedical NLP deserves better.